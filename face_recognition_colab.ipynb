{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ced5373",
   "metadata": {},
   "source": [
    "# Face Recognition — Google Colab (gcolab) notebook\n",
    "\n",
    "This notebook sets up a Colab-style environment, installs dependencies, mounts Google Drive, and runs the evaluation (`--eval`) of the `main.py` face recognition project. Select Runtime -> Change runtime type -> GPU before running cells for best performance.\n",
    "\n",
    "Sections:\n",
    "1. Install and import `gcolab` + dependencies\n",
    "2. Authenticate & mount Google Drive\n",
    "3. Initialize `gcolab` session and check runtime\n",
    "4. Upload / download files (Kaggle support)\n",
    "5. Sync workspace with Drive\n",
    "6. Run evaluation and save metrics\n",
    "7. Tests and troubleshooting tips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b35ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Install dependencies\n",
    "# Run these cells once. GPU runtime recommended (Runtime -> Change runtime type -> GPU).\n",
    "!pip install --upgrade pip\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 || pip install torch torchvision\n",
    "!pip install opencv-python-headless\n",
    "!pip install retina-face\n",
    "!pip install deepface\n",
    "!pip install kaggle\n",
    "!pip install gdown\n",
    "# Optional: `gcolab` is a Colab helper and is not published on PyPI.\n",
    "# Skip installing it when running locally — Colab provides it automatically.\n",
    "\n",
    "# Verify packages\n",
    "import sys, torch\n",
    "print('Python', sys.version)\n",
    "print('Torch CUDA available:', torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1df5ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2) Authenticate & mount Google Drive\n",
    "\n",
    "Use the cell below to mount your Google Drive. Place your project folder (or upload the repo zip) under `MyDrive/face_recognition`.\n",
    "\n",
    "If you want to use Kaggle datasets, upload your `kaggle.json` to the notebook (or place it in `~/.kaggle/kaggle.json`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130acb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set project path on Drive (adjust if you use a different folder)\n",
    "DRIVE_PROJECT = '/content/drive/MyDrive/face_recognition'\n",
    "\n",
    "import os\n",
    "if os.path.exists(DRIVE_PROJECT):\n",
    "    print('Found project folder on Drive:', DRIVE_PROJECT)\n",
    "else:\n",
    "    print('Drive mounted, create or upload your project to', DRIVE_PROJECT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d521971c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3) Initialize gcolab session & check runtime\n",
    "\n",
    "This cell shows how to initialize `gcolab` (if you want to use its helpers) and prints runtime info (GPU/CPU, Python version). If you don't want to use `gcolab`, skip these cells — mounting Drive and running shell commands works fine without it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1460ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize gcolab (optional)\n",
    "try:\n",
    "    import gcolab\n",
    "    print('gcolab version:', gcolab.__version__)\n",
    "except Exception as e:\n",
    "    print('gcolab not available or failed to import:', e)\n",
    "\n",
    "# Runtime info\n",
    "import platform\n",
    "print('Python', platform.python_version())\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print('CUDA not available')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2e370",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4) Upload / Download Files (Kaggle support)\n",
    "\n",
    "If you need a dataset from Kaggle, upload your `kaggle.json` (Account -> Create API token) and run the snippet below to download datasets. Alternatively, upload a zipped project to Drive and unzip into the workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b43541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: use Kaggle CLI to download a dataset (optional)\n",
    "# Upload kaggle.json to /root/.kaggle/kaggle.json first (use file upload in Colab UI)\n",
    "import os\n",
    "if os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print('Found kaggle.json')\n",
    "else:\n",
    "    print('If you need Kaggle, upload kaggle.json to /root/.kaggle/kaggle.json via the file upload UI')\n",
    "\n",
    "# Example command (uncomment and edit to use):\n",
    "# !kaggle datasets download -d <owner/dataset-name> -p /content --unzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b8113",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5) Sync Local Workspace with Drive\n",
    "\n",
    "Copy your project from Drive into the runtime workspace (`/content`) so the notebook can run `main.py` and use local paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1915b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy project from Drive into /content (adjust path to your Drive project folder)\n",
    "import shutil\n",
    "if os.path.exists(DRIVE_PROJECT):\n",
    "    print('Copying project to runtime...')\n",
    "    dst = '/content/face_recognition'\n",
    "    if os.path.exists(dst):\n",
    "        print('Removing existing runtime copy...')\n",
    "        shutil.rmtree(dst)\n",
    "    shutil.copytree(DRIVE_PROJECT, dst)\n",
    "    %cd /content/face_recognition\n",
    "    print('Files copied. Current dir:', os.getcwd())\n",
    "else:\n",
    "    print('Drive project not found; upload your project to the Drive path or upload files via the Colab UI')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329fb542",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6) Run evaluation and save metrics\n",
    "\n",
    "This cell runs `main.py --eval --fast` and captures output to `metrics.txt` and `metrics.json` (basic parsing). Adjust the command if your `main.py` path differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation and capture output\n",
    "import subprocess, shlex, json, re\n",
    "cmd = 'python main.py --eval --fast'\n",
    "print('Running:', cmd)\n",
    "proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "out_lines = []\n",
    "for line in proc.stdout:\n",
    "    print(line, end='')\n",
    "    out_lines.append(line)\n",
    "proc.wait()\n",
    "with open('metrics.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(out_lines)\n",
    "print('\\nMetrics written to metrics.txt')\n",
    "\n",
    "# Simple parsing example (extract key metrics)\n",
    "metrics = {}\n",
    "for L in out_lines:\n",
    "    m = re.match(r\"Overall Accuracy: ([0-9\\.]+) %\", L)\n",
    "    if m:\n",
    "        metrics['overall_accuracy'] = float(m.group(1))\n",
    "    m = re.match(r\"AUC: ([0-9\\.]+)\", L)\n",
    "    if m:\n",
    "        metrics['auc'] = float(m.group(1))\n",
    "    m = re.match(r\"EER: ([0-9\\.]+)\", L)\n",
    "    if m:\n",
    "        metrics['eer'] = float(m.group(1))\n",
    "\n",
    "with open('metrics.json','w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print('Parsed metrics saved to metrics.json', metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d794e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7) Download results and save to Drive\n",
    "\n",
    "Use the cell below to download `metrics.txt` or copy it back to Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the metrics file to local machine (Colab will show a download link)\n",
    "from google.colab import files\n",
    "files.download('metrics.txt')\n",
    "\n",
    "# Or copy to Drive\n",
    "import shutil\n",
    "if os.path.exists('/content/metrics.txt'):\n",
    "    shutil.copy('/content/metrics.txt', os.path.join(DRIVE_PROJECT, 'metrics.txt'))\n",
    "    print('Copied metrics.txt to Drive:', os.path.join(DRIVE_PROJECT, 'metrics.txt'))\n",
    "else:\n",
    "    print('metrics.txt not found')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
